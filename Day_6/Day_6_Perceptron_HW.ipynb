{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day-6-Perceptron-HW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFrUn9COcWKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5j_IK97b8DZ",
        "colab_type": "text"
      },
      "source": [
        "#Code perceptron from scratch, gates and early stopping implemented\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tM6Kf0Rb3pL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class binaryPerceptron:\n",
        "\n",
        "  def __init__(self, wts, th, alpha, tolerance = 1, patience = 5):\n",
        "    self.weights = np.asarray(wts).reshape(len(wts),1)\n",
        "    self.feature_length = len(self.weights)\n",
        "    self.th = th\n",
        "    self.learning_rate = alpha\n",
        "    self.tolerance = tolerance\n",
        "    self.patience = patience\n",
        "  \n",
        "  def activation(self, x):\n",
        "    return 1 if x > self.th else 0\n",
        "\n",
        "  def predict_single(self, x):\n",
        "    return self.activation(x.dot(self.weights).sum())\n",
        "\n",
        "  def predict(self, x):\n",
        "    y = np.zeros(len(x))\n",
        "    for i, item in enumerate(x):\n",
        "      y[i] = self.predict_single(item)\n",
        "    return y\n",
        "\n",
        "  def fit(self, x, y, iterations = 100):\n",
        "    e = 0\n",
        "    k = 0\n",
        "    for i in range(iterations):\n",
        "      t = self.learn_epoch(x,y)\n",
        "      if abs(t-e) < self.tolerance:\n",
        "        k += 1\n",
        "      else:\n",
        "        k = 0\n",
        "      if k >= self.patience:\n",
        "        print('Model has reached its capacity')\n",
        "\n",
        "  def learn_epoch(self, x, y):\n",
        "    e = 0\n",
        "    for feature, target in zip(x,y):\n",
        "      e += abs(self.learn_single(feature, target))\n",
        "    return e\n",
        "\n",
        "  def learn_single(self, x, y):\n",
        "    e = self.loss_func(y, self.predict_single(x))\n",
        "    dw = self.learning_rate * e * x.reshape(self.feature_length, 1)\n",
        "    self.weights += dw\n",
        "    return e\n",
        "\n",
        "  def loss_func(self, t, o):\n",
        "    return t - o"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFhhavGoqP6G",
        "colab_type": "text"
      },
      "source": [
        "##Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRSvWQmVjJHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_AND = np.array([0, 0, 0, 1])\n",
        "y_OR = np.array([0, 1, 1, 1])\n",
        "y_XOR = np.array([0, 1, 1, 0])\n",
        "w = np.array([0.3, -0.1])\n",
        "th =  0.2\n",
        "learning_rate = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNG4PIAkqRwn",
        "colab_type": "text"
      },
      "source": [
        "##AND Gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3ibsm_gplPU",
        "colab_type": "code",
        "outputId": "992aadef-83b8-423f-8094-215b33f89c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "p = binaryPerceptron(w, th, learning_rate)\n",
        "for i in range(10):\n",
        "  print(p.learn_epoch(x,y_AND))\n",
        "p.predict(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDGXNryOqUbI",
        "colab_type": "text"
      },
      "source": [
        "##OR Gate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "du1_p65epk3T",
        "colab_type": "code",
        "outputId": "a08ee5b1-bf53-4546-8f2f-65a1abe4560a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "p = binaryPerceptron(w, th, learning_rate)\n",
        "for i in range(10):\n",
        "  print(p.learn_epoch(x,y_OR))\n",
        "p.predict(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyDDjJuUqXOr",
        "colab_type": "text"
      },
      "source": [
        "##XOR Gate (Does not seem like it can be realised by a single perceptron)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83RKKJDOjM8f",
        "colab_type": "code",
        "outputId": "49848338-9fcd-4630-be51-919120fafdd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "p = binaryPerceptron(w, th, learning_rate)\n",
        "p.fit(x, y_XOR, iterations = 10)\n",
        "print(p.predict(x))\n",
        "print(p.weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 1.]\n",
            "[[0.2]\n",
            " [0.1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMmkAHbTp4DK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}